{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Fine-tuning LLM Guidance","text":"<p>(check lessons)</p> <p></p> <p>Once upon a digital age, nestled in the circuits and silicon valleys of our vast computational landscape, there resided a linguistic wizard known as LLM - the Large Language Model. It was a creature of great potential, with a voracious appetite for data and a profound ability to weave words into the very fabric of understanding. But to truly harness its powers for the tasks at hand, a grand adventure of fine-tuning awaited.</p>"},{"location":"#chapter-1-the-data-prep-chronicles","title":"Chapter 1: The Data Prep Chronicles","text":"<p>Our journey begins in the bustling metropolis of Data Prep, a place where raw information is transformed into glistening nuggets of knowledge. Here, the alchemists and data smiths worked tirelessly, curating and conditioning vast datasets. They meticulously cleaned, tokenized, and structured each piece, crafting a treasure trove of learning material fit for our wizard.</p>"},{"location":"#chapter-2-autotrains-magic-carpets","title":"Chapter 2: AutoTrain's Magic Carpets","text":"<p>With the data prepped, we turned to the enchanting AutoTrain, a mystical algorithmic carpet that would carry our LLM through the training skies. This was no ordinary ride; it was a carpet woven with self-optimizing threads, capable of navigating the vast expanses of parameter space with the grace of an algorithmic ballet. As it soared through epochs, the wizard LLM absorbed the essence of the data, its understanding deepening with every pass.</p>"},{"location":"#chapter-3-the-evaluation-trials","title":"Chapter 3: The Evaluation Trials","text":"<p>Training complete, the wizard faced the Evaluation Trials. A panel of sage metrics like ROUGE1, ROUGE2, and ROUGEL awaited, ready to put the wizard's newfound prowess to the test. The trials were rigorous, pushing the boundaries of summary and sentiment, challenging the wizard to demonstrate its mastery over the nuanced art of language.</p>"},{"location":"#chapter-4-the-black-box-enigma","title":"Chapter 4: The Black Box Enigma","text":"<p>But our tale does not end at the trials. For in the realm of machine learning, there lies the mysterious Black Box, a domain where decisions are made in shadows and reason is often cloaked in mystery. Our brave explorers ventured into this enigma, wielding tools of interpretability and transparency to shed light upon the wizard's inner workings. Each revelation was a victory, a step towards the demystification of the arcane.</p>"},{"location":"#epilogue-the-linguistic-wizards-legacy","title":"Epilogue: The Linguistic Wizard's Legacy","text":"<p>As our journey comes to a close, the linguistic wizard stands ready, its powers fine-tuned and its capabilities honed to near perfection. It now speaks with clarity and relevance, a testament to the trials, the data, and the countless cycles of learning it has undergone.</p> <p>In the annals of our digital domain, this adventure will be recounted as the time when humans and algorithms collaborated to create a linguistic wizard, a beacon of knowledge that could illuminate the path to understanding for all who sought its wisdom.</p> <p>And so, with a dash of data, a sprinkle of training, and a pinch of evaluation, the Large Language Model was ready to cast its spells upon the world, one word at a time.</p>"},{"location":"00_llm_intro/","title":"LLMs: an Introduction","text":""},{"location":"00_llm_intro/#2023-is-the-year-of-llm","title":"2023 is the Year of LLM","text":""},{"location":"00_llm_intro/#finetune-llms","title":"Finetune LLMs","text":"<p>Objectives</p> <p>Before we begin, let's review our objectives for finetuning LLMs:</p> <ul> <li>Define the goals of your project: what are you trying to accomplish?</li> <li>How can you evaluate the success of your project?</li> <li>What are the steps to finetune a LLM?</li> </ul>"},{"location":"00_llm_intro/#visualize-the-gpt-model","title":"Visualize the GPT Model","text":""},{"location":"01_data_prep/","title":"Data Preparation","text":"<p>In order to finetune the open sourced LLM, we need to follow the format they pre-trained.</p>"},{"location":"01_data_prep/#data-format","title":"Data Format","text":"base modelinstructed model <pre><code>&lt;s&gt; Below is xxx:\\n\\n### Instruction:\\n{instruction}\\n###Response:\\n{response}&lt;/s&gt;\n</code></pre> <pre><code>&lt;s&gt; [SYS] Below is xxx: [\\SYS]\\n\\n [INST]{instruction}[\\INST]{response}&lt;/s&gt;\n</code></pre>"},{"location":"01_data_prep/#jsonl","title":"JSONL","text":"<p>We will introduce <code>autotrain</code> later, the best format we used so far is based on <code>autotrain</code> with <code>jsonl</code> format.</p> text prompt example1 <code>&lt;s&gt;{info}&lt;/s&gt;</code> example2 <code>&lt;s&gt;{info}&lt;/s&gt;</code> Show me what you get! <p>All I can show is this: <pre><code>{\"text\": \"&lt;s&gt;{info}&lt;/s&gt;\"}\n{\"text\": \"&lt;s&gt;{info}&lt;/s&gt;\"}\n</code></pre> Please prepare something like this, and do not forget about <code>&lt;/s&gt;</code> to allow the model stop itself.</p>"},{"location":"01_data_prep/#case-study","title":"Case study","text":"<p>We will use <code>axs</code> and <code>CNN dailymail</code> as examples to show how we collect data to finetune the model here.</p> axsCNN dailymail <p>AXS is our internel toolbox, but we don't have good documentation for it yet. Thanks to LLM, we are exploring the possibility of using LLM as a smart assistant to help us to speed up the process of learning how to use AXS.</p> <p>CNN dailymail is a dataset for summarization. We will use it as an example to show how we collect data to finetune the model here.</p>"},{"location":"01_data_prep/#data-preparation_1","title":"Data Preparation","text":"<p>Follow the steps below to prepare your data:</p>"},{"location":"01_data_prep/#step-1-clone-the-repository-and-install-dependencies","title":"Step 1: Clone the Repository and install dependencies","text":"axsCNN dailymail <p>Clone the repository <pre><code>git clone https://github.com/krai/axs.git\n</code></pre></p> <p>Training dataset <pre><code>git lfs install\ngit clone https://huggingface.co/xihajun/cnn_dailymail\ncd cnn_dailymail\ngit lfs pull\n</code></pre></p> <p>Evaluation dataset <pre><code>git clone https://github.com/mlcommons/inference.git --depth 1\ncd inference/language/gpt-j/\npip install -r requirements.txt\npip install rouge-score\n</code></pre></p> Shell <p></p>"},{"location":"01_data_prep/#step-2-download-and-prepare-the-dataset","title":"Step 2: Download and prepare the dataset","text":"axsCNN dailymail <ul> <li>[ ] TODO: add the steps to prepare the dataset<ul> <li>[ ] commit messages</li> <li>[ ] hand written notes</li> <li>[ ] logs</li> <li>[ ] automation scripts</li> </ul> </li> </ul> <p>Prepare the training dataset with the <code>&lt;s&gt;&lt;/s&gt;</code> format (10K samples)</p> <pre><code>cd cnn_dailymail\npython3 filter_faster.py --input train_output.jsonl --output train_output_formatted.jsonl\nmkdir 10k\nhead -n10000 train_output_formatted.jsonl &gt; 10k/10k.jsonl\n</code></pre> <p>Download Evaluation dataset to <code>data</code> folder</p> <pre><code>cd inference/language/gpt-j/\npython3 download_cnndm.py\n</code></pre>"},{"location":"02_llm_finetune/","title":"LLM Finetune","text":"<p>Once you prepared your data, you can start to finetune the model. Let's assume that you have prepared your data in the following format:</p> <p><pre><code>{\"text\": \"&lt;s&gt;{info}&lt;/s&gt;\"}\n{\"text\": \"&lt;s&gt;{info}&lt;/s&gt;\"}\n</code></pre> and you have saved it as <code>train.jsonl</code> and <code>eval.jsonl</code> in the <code>data</code> folder.</p>"},{"location":"02_llm_finetune/#prepare-the-environment","title":"Prepare the environment","text":"<p>Huggingfaces' <code>autotrain</code> makes our life easier and have a great support from the github community. We will use it to finetune our model.</p> Install autotrainUse Docker to run autotrain <pre><code>pip install autotrain-advanced\n</code></pre> <pre><code>docker pull xihajun/autotrain-advanced\ndocker run -it --rm -v $(pwd):/workspace xihajun/autotrain-advanced\n</code></pre> Shell <p></p>"},{"location":"02_llm_finetune/#fine-tune-the-model","title":"Fine-tune the model","text":"usagemore details Optional <ul> <li>If you want to push your model to the hub, you need to create a token from here.</li> <li>wandb is a great tool to track your training process. You can create an account from here.</li> </ul> <pre><code>autotrain llm \\\n    --train \\\n    --model mistralai/Mistral-7B-v0.1 \\\n    --project-name finetuned_model \\\n    --data-path training_data/ \\\n    --text-column text \\\n    --lr 0.002 \\\n    --batch-size 16 \\\n    --epochs 30 \\\n    --block-size 1024 \\\n    --model_max_length 2048 \\\n    --warmup-ratio 0.1 \\\n    --lora-r 16 \\\n    --lora-alpha 32 \\\n    --lora-dropout 0.1 \\\n    --weight-decay 0.01 \\\n    --gradient-accumulation 4 \\\n    --fp16 \\\n    --use-peft \\\n    --use-int4 \\\n    --push-to-hub \\\n    --token &lt;your token&gt; \\\n    --repo-id xihajun/cnn_10k_0002_30_16_32_0.1_0.01 \\\n    --target-modules q_proj,v_proj \\\n    --log wandb \\\n    --save_total_limit 10 \\\n    --save_strategy epoch\n    --merge-adapter\n</code></pre> <p>autotrain llm </p> <p>--train --model mistralai/Mistral-7B-v0.1 --project-name mix_2000_autotrain_llm --data-path training_data/ --text-column text --lr 0.002 --batch-size 16 --epochs 30 --block-size 1024 --model_max_length 2048 --warmup-ratio 0.1 --lora-r 16 --lora-alpha 32 --lora-dropout 0.1 --weight-decay 0.01 --gradient-accumulation 4 --fp16 --use-peft </p> <p>--use-int4 </p> <p>--push-to-hub </p> <p>--token (1) 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 </p> <p>--repo-id xihajun/cnn_10k_0002_30_16_32_0.1_0.01 --target-modules q_proj,v_proj --log wandb --save_total_limit 10 --save_strategy epoch</p> <ol> <li> Your token</li> </ol> Shell <p></p>"},{"location":"02_llm_finetune/#self-assessment","title":"Self Assessment","text":"What is a Data Management Plan? <p>Important: A data management plan (DMP) is now required aspect of publicly funded research.</p> <p>DMPs are short, formal, documents outlining what types of data will be used, and what will be done with the data both during and after a research project concludes.</p> True or False: When science project funding ends, the data should end with it <p>False</p> <p>Data live on after a project ends.</p> <p>Ensuring that data have a full lifecycle where they can be (re)hosted and made available after a project ends is critical to open science and reproducible research</p> <p>Maybe</p> <p>Sometimes destroying data is part of the life cycle of data - this may be required if data are sensitive and could be used unethically in the future, beyond the control of the original investigator team. </p> True or False: FAIR and CARE data principles are the same <p>False</p> <p>The CARE principles were created in order to help guide and answer when and how applying FAIR data principles to soverign indigenous-controlled data should be done and when it should not. </p>"},{"location":"03_model_evaluation/","title":"Evaluating Models","text":"<p>Reference: https://github.com/krai/mistral7b_cnndailymail/tree/main/scripts/evaluation</p>"},{"location":"03_model_evaluation/#evaluation-metrics","title":"Evaluation Metrics","text":""},{"location":"03_model_evaluation/#rouge","title":"ROUGE","text":"<p>ROUGE is a tool for evaluating automatic summarization and machine translation software in natural language processing. The name ROUGE, in turn, is an acronym for Recall-Oriented Understudy for Gisting Evaluation.</p>"},{"location":"03_model_evaluation/#bleu","title":"BLEU","text":"<p>BLEU (bilingual evaluation understudy) is an algorithm for evaluating the quality of text which has been machine-translated from one natural language to another. Quality is considered to be the correspondence between a machine's output and that of a human: \"the closer a machine translation is to a professional human translation, the better it is\" \u2013 this is the central idea behind BLEU.</p>"},{"location":"03_model_evaluation/#meteor","title":"METEOR","text":"<p>METEOR (Metric for Evaluation of Translation with Explicit ORdering) is a metric for the evaluation of machine translation output. It is based on the harmonic mean of unigram precision and recall, with recall weighted higher than precision. It also has features that penalize output that is \"too good\" (i.e. over-generated).</p>"},{"location":"03_model_evaluation/#case-study","title":"Case study","text":"CNN Dailymailaxs MODEL_NAME Command 01-ai/Yi-6B <pre><code>python summarization_evaluator.py --model_name 01-ai/Yi-6B --data_file data/cnn_eval.json --num 100 --batch_size 5</code> </pre> xihajun/cnn_10k_0.001_30_16_32_0.1_0.01 <pre><code>python summarization_evaluator.py --model_name xihajun/cnn_10k_0.001_30_16_32_0.1_0.01 --data_file data/cnn_eval.json --num 100 --batch_size 5</code></pre> EleutherAI/gpt-j-6b <pre><code>python summarization_evaluator.py --model_name EleutherAI/gpt-j-6b --data_file data/cnn_eval.json --num 100 --batch_size 5</code></pre> <p>TBC</p>"},{"location":"04_black_box_enigma/","title":"Documentation &amp;  Communication","text":"<p>https://pytorch.org/tutorials/intermediate/model_parallel_tutorial.html</p> <p>Learning Objectives</p> <p>After this lesson, you should be able to:</p> <ul> <li>Identify and explain different types of project documentation (both internal and external)</li> <li>Describe tools and approaches to creating your own documentation</li> <li>Describe best practices for maintaining documentation</li> <li>Identify and explain different communication strategies for working in a team (virtual and in person)</li> <li>Create your own GitHub Pages website (!)</li> </ul> <p>Peer-reviewed manuscripts or conference preceedings / presentations /posters are one of the primary ways of communicating science, but they are far from the only avenues of communcation available to us as researchers and educators.</p> <p>As our methods become more complicated and customized, open science means giving people a better understanding of our approaches and tools than may be required in most journals. </p> <p>Communicating amongst a team of researchers that may span institutions, time zones, or continents also requires more modern approaches. </p> <p>Strong frameworks for internal communication and documentation can make collaboration easier, improve the quality of your science, and reduce the hassle of collaborative work.</p>"},{"location":"04_black_box_enigma/#project-documentation","title":"Project Documentation","text":"<p>Documentation is not only the practice of recording, preserving, and organizing information, data, or details in a structured and systematic manner. Documentation is essentially the ability to communicate with your future self, or your collaborators, or the world specific ideas and information. Effective documentation must take into consideration the following points:</p> <ul> <li> Clarity: Documentation should be easy to understand with clear language and no ambiguity.</li> <li> Completeness: It must cover all essential details, leaving nothing crucial undocumented.</li> <li> Accuracy: Information should be up-to-date and correct to prevent errors and misunderstandings.</li> <li> Organization: A logical structure and clear organization make it easy to navigate and find information.</li> <li> Relevance: Documentation should focus on what's pertinent to its intended audience or purpose, avoiding unnecessary information.</li> </ul> <p>We've already covered many best practices regarding project and data management, topics which are very much intertwined with documentation. Here are some things to keep in mind when addressing documentation:</p> <ul> <li>Metadata: Implement standardized metadata formats for research outputs to enhance findability.</li> <li>Data Repositories: Deposit research data and materials in trusted data repositories that adhere to FAIR principles, making them easily accessible and reusable.</li> <li>Persistent Identifiers: Assign persistent identifiers (e.g., DOIs, ORCIDs) to datasets, publications, and researchers, ensuring their long-term accessibility and recognition.</li> <li>Templates: Create and utilize documentation templates for research datasets, methods, and software to ensure uniform and comprehensive information capture. It saves time!!</li> </ul> <p>Not all documentation is the same. The documentation system, by Divio, categorizes the different types of documentation into 4 quadrants:</p> <p>  Read more in depth on the documentation system here: https://documentation.divio.com </p> Explanining the quadrants <ul> <li>Tutorials: Lessons! Tutorials are lessons that take the reader by the hand through a series of steps to complete a project of some kind. They are what your project needs in order to show a beginner that they can achieve something with it.</li> <li>How-to-guides: Recipes! How-to-guides take the reader through the steps required to solve a real-world problem.</li> <li>References: Guides! References offer technical descriptions of the machinery and how to operate it. References have one job only: to describe. They are code-determined, because ultimately that\u2019s what they describe: key classes, functions, APIs, and so they should list things like functions, fields, attributes and methods, and set out how to use them.</li> <li>Explanation: Discussions! The aims of explanations are to clarify and illuminate a particular topic by broadening the documentation\u2019s coverage of a topic.</li> </ul> <p>Furthermore, one of the main issues with documentation usually becomes keeping documents up-to-date. Here are some tips one can keep in mind to address the issue:</p> <ul> <li>Data Lifecycle Planning: Develop a clear data management and documentation plan at the outset of the research project to ensure consistency and continuity.</li> <li>Version Control: Use version control systems like Git for code and documentation to track changes, facilitate collaboration, and maintain a history of updates.</li> <li>Workflows and Automation: Explore automation tools for documentation, such as generating metadata from data headers or embedding documentation within code using tools like GitHub pages, Sphinx and LaTeX.</li> <li>Collaborative Documentation Platforms: Employ collaborative platforms like Overleaf or Google Docs to enable multiple researchers to contribute to and update documentation.</li> <li>Documentation Reviews: Schedule regular documentation reviews within research teams to identify gaps or outdated information and address them promptly.</li> </ul>"},{"location":"04_black_box_enigma/#public-repositories-for-documentation","title":"Public Repositories for Documentation","text":"<p>This website is rendered using  GitHub Pages using  MkDocs and the Material theme for MkDocs. </p> <p>Other popular website generators for GitHub Pages are  Jekyll Theme or  Bootstrap.js.</p> <p> ReadTheDocs.org has become a popular tool for developing web-based documentation. Think of RTD as \"Continuous Documentation\".</p> <p> Bookdown is an open-source R package that facilitates writing books and long-form articles/reports with R Markdown.</p> <p> Quarto is an open-source scientific and technical publishing system built on Pandoc</p> <p> Confluence Wikis (CyVerse) are another tool for documenting your workflow.</p> <p>Things to remember about Documentation</p> <ul> <li> <p>Documentation should be written in such a way that people who did not write the documentation can read and then use or read and then teach others in the applications of the material.</p> </li> <li> <p>Documentation is best treated as a living document, but version control is necessary to maintain it</p> </li> <li> <p>Technology changes over time, expect to refresh documentation every 3-5 years as your projects age and progress.</p> </li> </ul> <p> GitHub Pages</p> <ul> <li>You can pull templates from other GitHub users for your website,     e.g.  Jekyll themes</li> <li>GitHub pages are free, fast, and easy to build, but limited in use     of subdomain or URLs.</li> </ul> <p> ReadTheDocs</p> <ul> <li>publishing websites via     ReadTheDocs.com costs money.</li> <li>You can work in an offline state, where you develop the materials     and publish them to your localhost using     Sphinx</li> <li>You can work on a website template in a GitHub repository, and     pushes are updated in near real time using ReadTheDocs.com.</li> </ul> <p> Material MkDocs</p> <ul> <li>publish via GitHub Actions</li> <li>Uses open source Material or ReadTheDocs Themes</li> </ul> <p> Bookdown</p> <ul> <li>Bookdown websites can be hosted by RStudio     Connect</li> <li>You can publish a Bookdown website using Github     Pages</li> </ul> <p> Quarto</p> <ul> <li>Build a website using Quarto's template builder</li> <li>Build with Github Pages</li> </ul> <p> JupyterBook</p> <ul> <li>Based on Project Jupyter <code>ipynb</code> and MarkDown</li> <li>Uses <code>conda</code> package management</li> </ul> <p> GitBook</p> <ul> <li>GitBook websites use MarkDown syntax</li> <li>Free for open source projects, paid plans are available</li> </ul>"},{"location":"04_black_box_enigma/#websites-to-host-methods-protocols","title":"Websites to Host Methods &amp; Protocols","text":"<p>Open Science Framework for free. OSF can be directly linked to your ORCID.</p> <ul> <li>Integrated project management tools</li> <li>Uses templates to create a project website</li> <li>Can publish preprints from within project management tools</li> </ul> <p>Protocols.io - collaborative platform and preprint server for: science methods, computational workflows, clinical trials, operational procedures, safety checklists, and instructions / manuals.</p> <p>QUBES - community of math and biology educators who share resources and methods for preparing students to tackle real, complex, biological problems.</p> What are the benefits of using a GitHub.io website? <p>Github Pages are hosted directly from your GitHub repository. </p> <p>Just edit, push, and your changes are live.</p> <p>You do not need to run your own web server!!</p>"},{"location":"04_black_box_enigma/#communication","title":"Communication","text":""},{"location":"04_black_box_enigma/#internal-project","title":"Internal Project","text":"<p>Choosing which software to use for your internal lab communication can be complicated by the cost of setting up, the cost of maintaining, and simply by the sheer number of platforms that are out there.</p> <p>For this workshop, we use  SLACK (Searchable Log of All Conversation &amp; Knowledge). Microsoft's competitor to SLACK is  Microsoft Teams.</p> <p>Remember, the intention of these platforms are to improve productivity &amp; not become a distraction.</p> <p> SLACK</p> <ul> <li>Slack has plenty of apps for coordinating     multiple services, i.e. Calendars, Github, GoogleDrive, Box, etc.</li> <li>Free Slack is limiting (e.g., 90 day history; limited connections across workspaces).</li> <li>Paid Slack is $7.25 per user per month. (10 users for 1 year = $870)</li> </ul> <p> Microsoft Teams</p> <ul> <li>Teams is used by many R1 research universities as part of their     campus wide license agreement for Office 365 Business and Education</li> <li>For example, anyone with a <code>arizona.edu</code> email address can use Teams for free</li> <li>Limitations:<ul> <li>Not sure you can create your own Teams</li> <li>Limited to messaging with people in your university Team</li> </ul> </li> </ul> <p>Other popular alternatives</p> <ul> <li> BaseCamp</li> <li> Discord</li> <li> Mastodon</li> <li> Mattermost</li> </ul> <p>Useful links for creating a SLACK workspace</p> <pre><code>1.  [Create a new Workspace](https://get.slack.help/hc/en-us/articles/206845317-Create-a-Slack-workspace){target=_blank}\n2.  [Create channels, add apps &amp; tools](https://get.slack.help/hc/en-us/articles/217626298-tips-for-team-creators-and-admins){target=_blank}\n</code></pre>"},{"location":"04_black_box_enigma/#external-public","title":"External (Public)","text":"<p>Communicating with the public and other members of your science community (in addition to traditional peer-review publications and conferences) is one of the most important parts of your science!</p> <p>There are many ways scientists use social media and the web to share their data science ideas:</p> <ol> <li>:simple-twitter: \"Science Twitter\" -     is really just regular Twitter, but with a     focus on following other scientists and organizations, and tweeting     about research you're interested in. By building up a significant     following, more people will know you, know about your work, and     you'll have a higher likelihood of meeting other new collaborators.</li> <li>Blogging Platforms such as Medium are a great place to self publish your writing on just about any topic.     It's free to sign up and start blogging, but does have a fee for accessing premium content. Some of my favorite blogs include Toward Data Science     and Chris Holmes.</li> <li>Community groups - There are lists (and lists of lists) of     nationals research organizations,     in which a researcher can become involved. These older organziations     still rely on official websites, science journal blogs, and email     lists to communicate with their members. In the earth sciences there     are open groups which focus on communication like the Earth Science     Information Partners (ESIP) with     progressive ideas about how data and science can be done. Other     groups, like The Carpentries and     Research Bazaar are     focused on data science training and digital literacy.</li> <li>Podcasts - Creating and distributing audio content to masses is easier than ever before. There are many podcast hosting platforms including Spotify, Podbean, Acast, and Libsyn. From there is it simple to make your podcast availble in the Google Podcast app or Apple Podcast app. </li> <li>Webinars - With platforms such as Zoom, Microsoft Teams, and Google Meet, it is so easy nowadays to host a webinar touting and explaining your science. </li> <li>Youtube - The king of video sharing platforms is a great place to post content promoting your science (and yourself!). For example, Cyverse posts lots of content on cyberinfrastructure and data processing pipelines. Some of my favorite podcasts hosted on Youtube include StarTalk and Lex Fridman.</li> </ol> <p>Important</p> <pre><code>**Remember: Personal and Professional Accounts are Not Isolated**\n\nYou decide what you post on the internet. Your scientist identity may be\na part of your personal identity on social media, it might be separate.\nA future employer or current employer can see your old posts. What you\npost in your personal accounts can be considered a reflection of the\norganization you work for and may be used in decisions about hiring or\ndismissal.\n</code></pre>"},{"location":"04_black_box_enigma/#addressing-effective-communication","title":"Addressing Effective Communication","text":"<p>Whether internal or external, communication is important because it serves as the foundation for the exchange of information, ideas, and knowledge, enabling collaboration, understanding, and the advancement of individuals, organizations, and societies. It is therefore fundamental to be able to efficiently communicate, whether it is to promote a piece of scientific advancement, or reaching out to ask for help.</p> <p>The act of balancing transparency, openness, ethicality and respectful to personal data and intellectual property in communication has always been a challenge. A few methods to address these issues are the following:</p> <ul> <li> Utilize licensing options: Researchers can use open licensing mechanisms such as Creative Commons licenses to specify the terms under which their work can be shared, modified, and reused, balancing openness with protection.</li> <li> Data anonymization: To address privacy and ethical concerns, researchers can anonymize sensitive data before sharing it, allowing for openness without compromising privacy.</li> <li> Collaborative agreements: Collaborative research agreements and partnerships can define expectations regarding data sharing, authorship, and intellectual property, ensuring transparency while safeguarding interests.</li> <li> Transparent communication: Researchers can openly communicate their intentions and progress regarding sharing and publication, fostering trust and collaboration within the research community.</li> </ul> <p>Scientists might also want to keep in mind the following when addressing communication:</p> <ul> <li> Cultural shift: Resistance to open communication within traditional academic cultures can hinder progress. Taking initiative and demonstrating the advantages of scientific communication outside of the traditional methods (mail, journals) can really help with showing eagerness and devotion to an idea or project</li> <li> Accessibility and inclusivity: Ensuring that open communication is accessible to all, regardless of language, disability, or geographical location, is vital. Efforts to provide translations, accessible formats, and international collaboration can promote inclusivity.</li> <li> Quality control: Maintaining peer review and quality control in open access publications is essential. Initiatives like open peer review and establishing reputable open access journals can address this challenge.</li> <li> Advocacy and policy: Advocacy for open science policies at institutional and governmental levels can help overcome systemic barriers. Engaging with policymakers and advocating for open science initiatives is crucial.</li> </ul>"},{"location":"04_black_box_enigma/#hands-on-building-a-github-pages-website-using-mkdocs","title":"Hands-on: Building a GitHub Pages Website using MkDocs","text":"<p>This section is built in order to educate on and simplify the steps necessary that newcomers need to take in order to build a successful GitHub Pages hosted website. </p> <p>This tutorial is inspired by academicpages, a Jekyll themed template created in order to help scientists and academics build their own websites.</p> <p>The easy way would be to fork/import the foss-reference-hub website (repository) and modify it to reflect your requirements; this tutorial will cover the necessary files and repository structure you require in order to build a successful personal website.</p> <p>Repository Explanation</p> <p>A GitHub hosted website running the MkDocs-material theme requires the following files in order to function:</p> <ul> <li>A <code>docs</code> folder:<ul> <li>A folder that contains all the documents necessary to populate the website's pages.</li> <li>All of the documents that the user needs to change are in here.</li> </ul> </li> <li>A <code>mkdocs.yml</code> file:<ul> <li>A <code>yml</code> file which contains critical information on the website structure, including themes, fonts, and extensions.</li> </ul> </li> <li>A <code>requirements.txt</code> file:<ul> <li>A file with a list of software necessary to build the website, primilily used by GitHub Actions.</li> </ul> </li> <li>A <code>.github/workflow</code> folder:<ul> <li>Contains the <code>ghpages.yml</code> file that controls the GitHub Action.</li> </ul> </li> </ul> <p>The structure of the basic repository is the following:</p> <pre><code>.\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 mkdocs.yml              &lt;- Governing file for website building\n\u251c\u2500\u2500 requirements.txt        &lt;- Requirements file for pip installation (required by website)      \n\u251c\u2500\u2500 docs                           \n\u2502   \u251c\u2500\u2500 assets              &lt;- Folder for images and additional graphic assets\n\u2502   \u2514\u2500\u2500 index.md            &lt;- Main website home page\n\u2514\u2500\u2500 .github\n    \u2514\u2500\u2500 workflows\n        \u2514\u2500\u2500 ghpages.yml     &lt;- GitHub Actions controlling file\n</code></pre> <p>Upon pushing changes, a <code>gh-pages</code> branch will be automatically created by the GitHub Action; it is where the website is rendered from.</p>"},{"location":"04_black_box_enigma/#directions-a-forking-an-existing-repo","title":"Directions A: forking an existing repo","text":"<p>Prerequisites</p> <p>You will require the following in case you want to add code locally.</p> 1. Create a GitHub account <p>Navigate to the GitHub website and click Sign Up, and follow the on screen instructions.</p> 2. Generate a Token <p>You can follow the official documentation on how to generate Tokens here. We  discussed how to generate tokens in Week 0. Here's are quick steps you can follow in order to setup your account on your machine using tokens:</p> <ol> <li>On your coumputer:<ol> <li>Clone your repository (<code>git clone &lt;repository&gt;</code>)</li> <li>Make changes where necessary, and add (<code>git add &lt;changed files&gt;</code>), commit (<code>git commit -m \"&lt;message on changes&gt;\"</code>) and push your changes (<code>git push origin</code>).</li> <li>You should be prompted to logging in your GitHub account. Put your email but not your password. Instead, open your web browser and follow the steps below:</li> </ol> </li> <li>On GitHub:<ol> <li>Navigate to your GitHub Settings (You can access your account Settings from the dropdown menu where your account icon is, on the top right of the screen)</li> <li>Scroll to the bottom of the left hand side menu to find Developer settings and open it.</li> <li>Click Personal access tokens &gt; Tokens (classic)</li> <li>Click Generate new token &gt; Generate new token (classic). You might need to input your Authentification code if you have enabled 2FA.</li> <li>Give it a name, and all the scopes you require (tip: select all scopes and No Expiration), then click Generate Token. Copy the new generated Token</li> </ol> </li> <li>Back on your computer:<ol> <li>If you have been following the steps above, you should still be in your shell with GitHub still asking for your password.</li> <li>Paste your Token here, and you should be logging in. Your changes should then be saved to GitHub.</li> </ol> </li> </ol> <ol> <li>Fork or import the FOSS Reference Hub website tutorial repository branch<ul> <li>Forking or importing will allow you to have your own copy of a specific repository; Cloning a repository without forking/importing it first, will lead to changes not being applied to your own copy of the repo, but to the original repository. You should clone your forked or imported repository, not the original!</li> </ul> </li> <li>Navigate to Settings &gt; Actions &gt; General:<ul> <li>Under Action Permissions select Allow all actions and reusalbe workflows</li> <li>Under Workflow permissions select Read and write permissions and Allow GitHub Actions to create and approve pull requests</li> </ul> </li> <li>Edit the <code>mkdocs.yml</code> and push your changes<ul> <li>The first changes you should be making are in the first few lines in the <code>mkdocs.yml</code> file in order to reflect your necessities:<ul> <li>Line 1: <code>site_name:</code> change to any title you want for your website </li> <li>Line 2: <code>site_description:</code> give a short description of the website</li> <li>Line 3: <code>site_author:</code> who you are</li> <li>Line 4: <code>site_url:</code> change it to the URL reflected in Settings, which will most likely be <code>https://&lt;github-username.github.io&gt;/</code></li> <li>Line 7: <code>repo_name:</code> give the name of your repository (e.g., <code>academicpages-mkdocs</code> in this case)</li> <li>Line 8: <code>repo_url:</code> give the git repository URL </li> <li>Line 11: <code>copyright:</code> change <code>your name</code> to the maintainer of the website (likely to be you)</li> </ul> </li> </ul> <p>Workflow expectations</p> <p>The previos changes should trigger the GitHub action workflow, which is setup to apply changes to the website every time a commit is pushed. One of the first thing that <code>mkdocs-material</code> will do, is to create the <code>gh-pages</code> branch (in case you do not have it already). The workflow will fail because the <code>ghpages.yml</code> in the <code>.github/workflows</code> directory is disabled (\"commented out\"). To enable it, remove the <code>#</code> at the beginnig on each line and commit your changes. Upon changes, the workflow should go ahead and create the <code>gh-pages</code> branch.</p> </li> <li>Navigate to Settings &gt; Pages and make sure that Source is Deploy from a branch and Branch is gh-pages, /(root)<ul> <li>You should be able to access your website at <code>https://&lt;github-username&gt;.github.io/</code>. If you cannot find your website, go to the repository's settings page and navigate to Pages: your website address will be there.</li> </ul> </li> <li>Edit documents as necessary.<ul> <li>Don't forget to add, commit and push changes!</li> <li>Changes will only be visible on the website after a successful push.</li> <li>After each push, next to the commit identifier GitHub will show either a yellow circle (, meaning building), green check (, meaning success), or red cross (, meaning failure).</li> </ul> Failure? Try again! <p>If you've been given the red cross , GitHub will notify you with what went wrong. By clicking on the , GitHub will open up a new page showing you the broken process.</p> </li> </ol>"},{"location":"04_black_box_enigma/#directions-b-creating-your-own","title":"Directions B: Creating your own","text":"<p>Prerequisites</p> <p>You will require the following in case you want to add code locally. However, you can do all of these changes directly on GitHub. If you do want to carry out changes locally, you'll need the a GitHub account and a Token.</p> 1. Create a GitHub account <p>Navigate to the GitHub website and click Sign Up, and follow the on screen instructions.</p> 2. Generate a Token <p>You can follow the official documentation on how to generate Tokens here. We  discussed how to generate tokens in Week 0. Here's are quick steps you can follow in order to setup your account on your machine using tokens:</p> <ol> <li>On your coumputer:<ol> <li>Clone your repository (<code>git clone &lt;repository&gt;</code>)</li> <li>Make changes where necessary, and add (<code>git add &lt;changed files&gt;</code>), commit (<code>git commit -m \"&lt;message on changes&gt;\"</code>) and push your changes (<code>git push origin</code>).</li> <li>You should be prompted to logging in your GitHub account. Put your email but not your password. Instead, open your web browser and follow the steps below:</li> </ol> </li> <li>On GitHub:<ol> <li>Navigate to your GitHub Settings (You can access your account Settings from the dropdown menu where your account icon is, on the top right of the screen)</li> <li>Scroll to the bottom of the left hand side menu to find Developer settings and open it.</li> <li>Click Personal access tokens &gt; Tokens (classic)</li> <li>Click Generate new token &gt; Generate new token (classic). You might need to input your Authentification code if you have enabled 2FA.</li> <li>Give it a name, and all the scopes you require (tip: select all scopes and No Expiration), then click Generate Token. Copy the new generated Token</li> </ol> </li> <li>Back on your computer:<ol> <li>If you have been following the steps above, you should still be in your shell with GitHub still asking for your password.</li> <li>Paste your Token here, and you should be logging in. Your changes should then be saved to GitHub.</li> </ol> </li> </ol> <ol> <li>Create your own repository<ul> <li>Add a README and a license and keep the repository public</li> </ul> </li> <li>Create a <code>docs</code> folder<ul> <li>Within the folder, create an <code>index.md</code> file</li> </ul> </li> <li>Navigate to Settings &gt; Actions &gt; General:<ul> <li>Under Action Permissions select Allow all actions and reusalbe workflows</li> <li>Under Workflow permissions select Read and write permissions and Allow GitHub Actions to create and approve pull requests</li> </ul> </li> <li> <p>Create an <code>requirements.txt</code> file and populate it with the following requirement list:</p> Expand for code! <pre><code>bump2version\ncoverage\nflake8\ngrip\nipykernel\nlivereload\nnbconvert&gt;=7\npip\nsphinx\ntox\ntwine\nwatchdog\nwheel\nmkdocs-git-revision-date-plugin \nmkdocs-jupyter \nmkdocs-material \nmkdocs-pdf-export-plugin\nmkdocstrings \nmkdocstrings-crystal\nmkdocstrings-python-legacy\n#pygments&gt;=2.10,&lt;2.12\n#pymdown-extensions&lt;9.4\n\n# Requirements for core\njinja2&gt;=3.0.2\nmarkdown&gt;=3.2\nmkdocs&gt;=1.4.0\nmkdocs-material-extensions&gt;=1.0.3\npygments&gt;=2.12\npymdown-extensions&gt;=9.4\n\n# Requirements for plugins\nrequests&gt;=2.26\n</code></pre> </li> <li> <p>Create an <code>mkdocs.yml</code> file and  populate it with the following:</p> Expand for code! <pre><code>site_name: Name of your website\nsite_description: Tell people what this website is about\nsite_author: Who you are\nsite_url: The website URL\n\n# Repository\nrepo_name: The repository name\nrepo_url: The repository URL\nedit_uri: edit/main/docs/\n# Copyright\ncopyright: 'Copyright &amp;copy; 2023 - 2024'\n\n\n# Configuration\ntheme:\n    name: material\nhighlightjs: true\nfont:\n    text: Roboto\n    code: Regular\npalette:\n    scheme: default\n\n# Features  \nfeatures:\n- navigation.instant\n- navigation.tracking\n- navigation.tabs\n- navigation.tabs.sticky\n- navigation.indexes\n- navigation.top\n- toc.follow\n\n# 404 page\nstatic_templates:\n    - 404.html\n\n# Search feature\ninclude_search_page: false\nsearch_index_only: true\n\n# Palette and theme (uses personalized colours)\nlanguage: en\npalette:\n    primary: custom\n    accent: custom\nicon:\n    logo: material/cogs\n    favicon: material/cogs\n\n# Page tree\nnav:\n- Home: index.md\n\n# Extra Plugins\nplugins:\n    - search\n    - mkdocstrings\n    - git-revision-date\n    - mkdocs-jupyter:\n        include_source: True\n        ignore_h1_titles: True\n\n# Extensions (leave as is)\nmarkdown_extensions:\n- admonition\n- abbr\n- attr_list\n- def_list\n- footnotes\n- meta\n- md_in_html\n- toc:\n    permalink: true\n    title: On this page\n- pymdownx.arithmatex:\n    generic: true\n- pymdownx.betterem:\n    smart_enable: all\n- pymdownx.caret\n- pymdownx.critic\n- pymdownx.details\n- pymdownx.emoji:\n    emoji_index: !!python/name:materialx.emoji.twemoji\n    emoji_generator: !!python/name:materialx.emoji.to_svg\n- pymdownx.highlight\n- pymdownx.inlinehilite\n- pymdownx.keys\n- pymdownx.magiclink:\n    repo_url_shorthand: true\n    user: squidfunk\n    repo: mkdocs-material\n- pymdownx.mark\n- pymdownx.smartsymbols\n- pymdownx.superfences:\n    custom_fences:\n        - name: mermaid\n        class: mermaid\n        format: !!python/name:pymdownx.superfences.fence_code_format\n- pymdownx.tabbed\n- pymdownx.tasklist:\n    custom_checkbox: true\n- pymdownx.tilde\n</code></pre> </li> <li> <p>Create a <code>.github/workflows</code> folder and add a <code>ghpages.yml</code> with the following:</p> Expand for code! <pre><code>name: Publish docs via GitHub\non:\npush:\n    branches:\n    - main\n\njobs:\nbuild:\n    name: Deploy docs\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v3\n    - uses: actions/setup-python@v4\n        with:\n        python-version: 3.9\n    - name: run requirements file\n        run:  pip install -r requirements.txt \n    - name: Deploy docs\n        run: mkdocs gh-deploy --force\n        env:\n        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n</code></pre> </li> <li> <p>Navigate to Settings &gt; Pages and make sure that Source is Deploy from a branch and Branch is gh-pages, /(root)</p> <ul> <li>You should be able to access your website at <code>https://&lt;github-username&gt;.github.io/</code>. If you cannot find your website, go to the repository's settings page and navigate to Pages: your website address will be there.</li> </ul> </li> <li>Edit documents as necessary.<ul> <li>Don't forget to add, commit and push changes!</li> <li>Changes will only be visible on the website after a successful push.</li> <li>After each push, next to the commit identifier GitHub will show either a yellow circle (, meaning building), green check (, meaning success), or red cross (, meaning failure).</li> </ul> </li> </ol>"},{"location":"04_black_box_enigma/#further-documentation","title":"Further Documentation","text":"<p>Here are some guides that you may find useful:</p> <ul> <li>MarkDown cheatsheet: for correct MarkDown synthax.</li> <li>MkDocs-material: a starting guide to MkDocs Material theme (massive list of supported emojis here).</li> <li>MkDocs-material References: more sophisticated documentation for MkDocs Material. </li> <li>YouTube link to FOSS 2022: Michael explains (~1h mark) his Jekyll-based website and gives a tutorial on how to use academicpages.</li> </ul>"},{"location":"04_black_box_enigma/#self-paced-material","title":"Self-Paced Material","text":"<ul> <li>15 Data Science Communities to Join</li> <li>Python &amp; Slack</li> <li>Slack CLI notifications</li> <li>Meetups</li> </ul>"},{"location":"04_black_box_enigma/#github-pages-website-quickstarts","title":"GitHub Pages Website Quickstarts","text":"<ul> <li> <p> GitHub Pages</p> <ol> <li>Create a GitHub account</li> <li>Clone the repo <code>https://github.com/username/username.github.io</code></li> <li>Create an <code>index.html</code></li> <li>Push it back to GitHub</li> </ol> </li> <li> <p> ReadTheDocs.org</p> <ol> <li>Install</li> <li>Use Github</li> <li>Create a ReadTheDocs account</li> </ol> </li> <li> <p> Material MkDocs</p> <ol> <li>Install Material <ol> <li>use a <code>reqirements.txt</code> </li> <li>or <code>pip install mkdocs-material</code></li> </ol> </li> <li>Clone a repository with an existing template or create a new repo with <code>mkdocs new .</code> </li> <li>Run <code>python -m mkdocs serve</code> to build and serve locally</li> <li>Open your browser to preview the build at https://localhost:8000`</li> </ol> </li> <li> <p> Bookdown</p> <ol> <li>Install R and RStudio</li> <li>Install Bookdown package with <code>install.packages(\"bookdown\", dependencies=TRUE)</code></li> <li>Open the Bookdown demo and get started</li> </ol> </li> <li> <p> Quarto</p> <ul> <li>Follow these instructions</li> </ul> </li> <li> <p> JupyterBook</p> <ul> <li>Create your first book</li> </ul> </li> <li> <p> GitBook</p> <ul> <li>Follow Template builder</li> </ul> </li> </ul>"},{"location":"04_black_box_enigma/#self-assessment","title":"Self Assessment","text":"True or False: Tutorials and How-to-Guides are the same <p>False</p> <p>Tutorials are in general introductory and longer than How-to-Guides and are intended for teaching learners a new concept by describing applications and providing justifications. </p> <p>How-to-Guides are more like cooking recipes which include step-by-step instructions for a specific task.</p> True or False: Teams should communicate over a single messaging platform. <p>False</p> <p>While it may be advisable to push informal communication toward a platform like SLACK or Microsoft Teams, there is no one-platform-fits-all solution for managing a diverse science team.</p> What is the best communication platform for team science? <p>There is no best platform, but there are some best practices</p> <p>In general, communications amongst team members may be best suited for messaging services like SLACK, Teams, or Chat.</p> <p>For software development, GitHub Issues are one of the primary means of documenting changes and interactions on the web.</p> <p>Formal communication over email is preferred, and is necessary for legal, budgetary, and institutional interactions.</p>"},{"location":"05_common_issues/","title":"Common Issues","text":""},{"location":"05_common_issues/#q-reproducibility-of-results","title":"Q: Reproducibility of results","text":"<ul> <li>[ ] Generative model is non-deterministic, but as far as I know the temperature could be a parameter to control the randomness.</li> </ul>"},{"location":"06_resources/","title":"Good Resources","text":""},{"location":"06_resources/#opt-training-log-book","title":"OPT training LOG BOOK","text":"<p>https://github.com/facebookresearch/metaseq/tree/main/projects/OPT/chronicles s</p>"},{"location":"07_cicd/","title":"Workflow","text":""},{"location":"07_cicd/#github-actions-workflow-tutorial-check-resources","title":"GitHub Actions Workflow Tutorial: \"Check Resources\"","text":"<p>This GitHub Actions workflow, named \"Check Resources,\" is designed to automate the process of testing machine performance and resource availability for different configurations. Here's a breakdown of its components:</p>"},{"location":"07_cicd/#workflow-trigger","title":"Workflow Trigger","text":"<ul> <li>On Push: Activates on a push to the <code>cicd_test</code> branch.</li> <li>Workflow Dispatch: Allows manual triggering with an input option to select a specific machine or all machines.</li> </ul>"},{"location":"07_cicd/#jobs-overview","title":"Jobs Overview","text":"<p>The workflow consists of several jobs, each performing specific tasks:</p> <ol> <li><code>prepare-matrix</code>: Sets up a matrix of machines to test.</li> <li><code>check-runner-availability</code>: Ensures the specified runner machine is available.</li> <li><code>get-loadgen-target-qps</code>: Calculates the Queries Per Second (QPS) matrix for load generation.</li> <li><code>check-resources-and-run</code>: Checks resource availability and runs tests.</li> <li><code>summary</code>: Summarizes and comments on the test results.</li> </ol>"},{"location":"07_cicd/#workflow-execution","title":"Workflow Execution","text":"<ul> <li>The workflow follows a sequential and conditional execution pattern, ensuring that each step is dependent on the success of the previous steps.</li> <li>It efficiently manages resources, like Docker containers, and ensures clean-up after tests.</li> <li>The results from the testing are saved, uploaded, and summarized for easy review.</li> </ul> <p>This workflow demonstrates a comprehensive approach to testing and resource management, leveraging GitHub Actions' capabilities to automate complex CI/CD processes.</p> <p>Certainly! Here's the breakdown of the GitHub Actions workflow \"Check Resources\" along with the relevant code snippets for each job:</p>"},{"location":"07_cicd/#job-1-prepare-matrix","title":"Job 1: <code>prepare-matrix</code>","text":"<p>This job sets up a matrix of machines to test, determining which machines should be included based on the trigger event.</p> <ul> <li>Runs On: The latest Ubuntu runner.</li> <li>Purpose: Dynamically creates a matrix of machines based on the trigger event.</li> <li>Steps:</li> <li>Checks if the workflow is triggered by a push or a manual dispatch and sets the machine matrix accordingly.</li> </ul> Code <pre><code>prepare-matrix:\n  runs-on: ubuntu-latest\n  outputs:\n    matrix: ${{ steps.set-matrix.outputs.matrix }}\n  steps:\n  - name: Set Running Machine Matrix\n    id: set-matrix\n    run: |\n      if [[ \"${{ github.event_name }}\" == \"push\" ]]; then\n        echo \"matrix=$MACHINE_LIST\" &gt;&gt; $GITHUB_OUTPUT\n      elif [[ \"${{ github.event.inputs.machine }}\" == \"all\" ]]; then\n        echo \"matrix=$MACHINE_LIST\" &gt;&gt; $GITHUB_OUTPUT\n      else\n        echo \"matrix=[\\\"${{ github.event.inputs.machine }}\\\"]\" &gt;&gt; $GITHUB_OUTPUT\n      fi\n</code></pre>"},{"location":"07_cicd/#job-2-check-runner-availability","title":"Job 2: <code>check-runner-availability</code>","text":"<p>Dependent on <code>prepare-matrix</code>, this job ensures the specified runner machine is available.</p> <ul> <li>Dependency: Needs <code>prepare-matrix</code> to complete first.</li> <li>Runs On: The machine specified in the matrix.</li> <li>Timeout: Set to 2 minutes.</li> <li>Purpose: Verifies that the selected runner is available.</li> <li>Steps:</li> <li>Prints a confirmation message once the runner is assigned.</li> </ul> Code <pre><code>check-runner-availability:\n  needs: prepare-matrix\n  runs-on: ${{ matrix.machine }}\n  timeout-minutes: 2\n  strategy:\n    matrix:\n      machine: ${{fromJson(needs.prepare-matrix.outputs.matrix)}}\n  steps:\n  - name: Wait for runner\n    run: |\n      echo \"Runner ${{ matrix.machine }} assigned and job started.\"\n</code></pre>"},{"location":"07_cicd/#job-3-get-loadgen-target-qps","title":"Job 3: <code>get-loadgen-target-qps</code>","text":"<p>This job calculates the Queries Per Second (QPS) matrix for load generation, depending on <code>check-runner-availability</code>.</p> <ul> <li>Dependency: Requires <code>check-runner-availability</code>.</li> <li>Runs On: Ubuntu latest.</li> <li>Purpose: Computes a range of QPS values for testing.</li> <li>Steps:</li> <li>Runs a script to generate a sequence of QPS values and sets it as an output.</li> </ul> Code <pre><code>get-loadgen-target-qps:\n  needs: check-runner-availability\n  runs-on: ubuntu-latest\n  outputs:\n    qps_matrix: ${{ steps.set-qps.outputs.qps_matrix }}\n  steps:\n  - name: Calculate QPS Matrix\n    id: set-qps\n    run: |\n      current_qps=1000  # Replace with actual value\n      one_percent=$((current_qps / 100))\n      qps_matrix=$(seq $((current_qps - one_percent)) $one_percent $((current_qps + one_percent)) | tr '\\n' ',' | sed 's/,$//')\n      qps_matrix=\"[$qps_matrix]\"\n      echo \"::set-output name=qps_matrix::$qps_matrix\"\n</code></pre>"},{"location":"07_cicd/#job-4-check-resources-and-run","title":"Job 4: <code>check-resources-and-run</code>","text":"<p>After <code>check-runner-availability</code> and <code>get-loadgen-target-qps</code>, this job checks resource availability and runs tests.</p> <ul> <li>Dependencies: Waits for <code>check-runner-availability</code> and <code>get-loadgen-target-qps</code>.</li> <li>Runs On: The machine specified in the matrix.</li> <li>Strategy: Defines a matrix with multiple parameters like machine, QPS, framework, and device.</li> <li>Steps:</li> <li>Code Checkout: Checks out the repository code.</li> <li>Docker Container Management: Manages Docker containers based on their availability.</li> <li>Resource Checking: Determines the number of devices and checks card availability.</li> <li>Experiment Execution: Runs accuracy and performance tests if resources are available.</li> <li>Docker Cleanup: Stops and removes the Docker container.</li> <li>Result Handling: Prints, saves, and uploads test results.</li> </ul> Code <pre><code>check-resources-and-run:\n  needs: [check-runner-availability, get-loadgen-target-qps]\n  runs-on: ${{ matrix.machine }}\n  strategy:\n    matrix:\n      machine: ${{fromJson(needs.check-runner-availability.outputs.matrix)}}\n      loadgen_target_qps: ${{fromJson(needs.get-loadgen-target-qps.outputs.qps_matrix)}}\n      framework: ['kilt']\n      device: ['qaic']\n      loadgen_scenario: ['Offline', 'Server']\n      config: \n        - {model: 'resnet50', benchmark_type: 'image_classifier', container: 'krai/axs.resnet50', special_params: ''}\n  steps:\n  # Steps for checking out code, managing Docker container, checking resources, running experiments, handling results, etc.\n</code></pre>"},{"location":"07_cicd/#job-5-summary","title":"Job 5: <code>summary</code>","text":"<p>The final job summarizes and comments on the test results.</p> <ul> <li>Dependency: Needs <code>check-resources-and-run</code> to complete.</li> <li>Runs On: Ubuntu latest.</li> <li>Purpose: Creates a summary of the test results.</li> <li>Steps:</li> <li>Checks out the code, downloads all artifacts, generates a summary, and comments on an issue with the results.</li> </ul> Code <pre><code>summary:\n  needs: check-resources-and-run\n  runs-on: ubuntu-latest\n  steps:\n  - name: Check out code\n    uses: actions/checkout@v3\n  - name: Download all artifacts\n    uses: actions/download-artifact@v2\n  - name: Execute Summary Script\n    run: |\n      chmod +x .github/scripts/summary/generate_summary.sh\n      ./.github/scripts/summary/generate_summary.sh\n  - name: Comment on the issue\n    uses: peter-evans/create-or-update-comment@v3\n    with:\n      issue-number: 115\n      body-path: 'table.md'\n</code></pre>"},{"location":"code_of_conduct/","title":"Code of Conduct","text":"<p>In conjunction with for using CyVerse cyberinfrastructure, this Code of Conduct applies to all Event participants and their activities while using CyVerse resources and/or attending the Event.</p> <p>CyVerse is dedicated to providing professional computational research and educational experiences for all of our users, regardless of domain focus, academic status, educational level, gender/gender identity/expression, age, sexual orientation, mental or physical ability, physical appearance, body size, race, ethnicity, religion (or lack thereof), technology choices, dietary preferences, or any other personal characteristic.</p> <p>When using CyVerse or participating at an Event, we expect you to:</p> <ul> <li>Interact with others and use CyVerse professionally and ethically by     complying with our Policies.</li> <li>Constructively critize ideas and processes, not people.</li> <li>Follow the Golden Rule (treat others as you want to be treated) when     interacting online or in-person with collaborators, trainers, and     support staff.</li> <li>Comply with this Code in spirit as much as the letter, as it is     neither exhaustive nor complete in identifying any and all possible     unacceptable conduct.</li> </ul> <p>We do not tolerate harassment of other users or staff in any form (including, but not limited to, violent threats or language, derogatory language or jokes, doxing, insults, advocating for or encouraging any of these behaviors). Sexual language and imagery are not appropriate at any time (excludes Protected Health Information in compliance with HIPAA). Any user violating this Code may be expelled from the platform and the workshop at CyVerse's sole discretion without warning.</p> <p>To report a violation of this Code, directly message a trainer via Slack or email info@cyverse.org with the following information:</p> <ul> <li>Your contact information</li> <li>Names (real, username, pseudonyms) of any individuals involved, and     or witness(es) if any.</li> <li>Your account of what occurred and if the incident is ongoing. If     there is a publicly available record (a tweet, public chat log,     etc.), please include a link or attachment.</li> <li>Any additional information that may be helpful in resolving the     issue.</li> </ul>"},{"location":"glossary/","title":"Glossary &amp; Acronyms","text":"<p>A</p> <ul> <li>action: automate a workflow in the context of CI/CD, see GitHub Actions</li> <li>agile: development methodology     for organizing a team to complete tasks organized over short periods     called 'sprints'</li> <li>allocation: portion of a resource assigned to a particular     recipient, typical unit is a core or node hour</li> <li>Anaconda: open source data science platform.     Anaconda.com</li> <li>application: also called an 'app', a software designed to help     the user to perform specific task</li> <li>awesome: a curated set of lists that provide insight into     awesome software projects on GitHub</li> <li>AVU: Attribute-Value-Unit a components for iRODS     metadata.</li> </ul> <p>B</p> <ul> <li>beta: a software version which is not yet ready for     publication but is being tested</li> <li>bash: Bash is the GNU Project's shell, the Bourne-Again     Shell</li> <li>biocontainer: a community-driven project that provides the     infrastructure and basic guidelines to create, manage and distribute     bioinformatics packages (e.g conda) and containers (e.g docker,     singularity)</li> <li>bioconda: a channel for the conda package manager specializing     in bioinformatics software</li> </ul> <p>C</p> <ul> <li>CLI: the UNIX shell command line interface,     most typically BASH</li> <li>command: a set of instructions sent to the computer, typically     in a typed interface</li> <li>conda: an installation type of the Anaconda data science     platform. Command line application for managing packages and     environments</li> <li>container: virtualization of an operating system run within an     isolated user space</li> <li>Continuous Integration: (CI) is testing automation to check that     the application is not broken whenever new commits are integrated     into the main branch</li> <li>Continuous Delivery: (CD) is an extension of 'continuous     integration' to make sure that you can release new changes in a     sustainable way</li> <li>Continuous Deployment: a step further than 'continuous     delivery', every change that passes all stages of your production     pipeline is released</li> <li>Continuous Development: a process for iterative software     development and is an umbrella over several other processes     including 'continuous integration', 'continuous testing',     'continuous delivery' and 'continuous deployment'</li> <li>Continuous Testing: a process of testing and automating software     development.</li> <li>CRAN: The Comprehensive R Archive     Network</li> <li>CyVerse tool: Software program that is integrated into the back     end of the DE for use in DE apps</li> <li>CyVerse app: graphic interface of a tool made available for use     in the DE</li> </ul> <p>D</p> <ul> <li>Debian: a free OS, base of other     Linux distributions such as Ubuntu</li> <li>Development: the environment on your computer where you write     code</li> <li>DevOps Software *Dev*elopment and information techology     *Op*erations techniques for shortening the time to change software     in relation to CI/CD</li> <li>Discovery Environment (DE): a data science workbench for running     executable, interactive, and high throughput applications in     CyVerse DE</li> <li>distribution: abbreviated as 'distro', an operating system     made from a software collection based upon the Linux kernel</li> <li>Docker: Docker is an open source     software platform to create, deploy and manage virtualized     application containers on a common operating system (OS), with an     ecosystem of allied tools. A program that runs and handles     life-cycle of containers and images</li> <li>DockerHub: an official registry of docker containers, operated     by Docker. DockerHub</li> <li>DOI: a digital object identifier. A persistant identifier     number, managed by the doi.org</li> <li>Dockerfile: a text document that contains all the commands you     would normally execute manually in order to build a Docker image.     Docker can build images automatically by reading the instructions     from a Dockerfile</li> </ul> <p>E</p> <ul> <li>environment: software that includes operating system, database     system, specific tools for analysis</li> <li>entrypoint: In a Dockerfile, an ENTRYPOINT is an optional     definition for the first part of the command to be run</li> </ul> <p>F</p> <ul> <li>FOSS: (1) Free and Open Source Software, (2)     Foundational Open Science Skills - this class!</li> <li>function: a named section of a program that performs a specific     task</li> </ul> <p>G</p> <ul> <li>git: a version control system software</li> <li>gitter: a Github based messaging service that uses markdown     gitter.im</li> <li>GitHub: a website for hosting <code>git</code> repositories - owned by     Microsoft GitHub</li> <li>GitLab: a website for hosting <code>git</code> repositories     GitLab</li> <li>GitOps: using <code>git</code> framework as a means of deploying     infrastructure on cloud using Kubernetes</li> <li>GPU: graphic processing unit</li> <li>GUI: graphical user interface</li> </ul> <p>H</p> <ul> <li>hack: a quick job that produces what is needed, but not well</li> <li>HPC: High Performance Computer, for large syncronous computation</li> <li>HTC: High Throughput Computer, for many parallel tasks</li> </ul> <p>I</p> <ul> <li>IaaS: Infrastructure as a Service.     online services that provide APIs</li> <li>iCommands: command line application for     accessing iRODS Data Store</li> <li>IDE: integrated development environment, typically a graphical     interface for working with code language or packages</li> <li>instance: a single virtul machine</li> <li>image: self-contained, read-only 'snapshot' of your applications     and packages, with all their dependencies</li> <li>iRODS: an open source integrated Rule-Oriented Data Management     System, iRODS.org</li> </ul> <p>J</p> <ul> <li>Java: programming language, class-based, object-oriented</li> <li>JavaScript: programming language</li> <li>JSON: Java Script Object Notation, data interchange format that     uses human-readable text</li> <li>Jupyter(Hub,Lab,Notebooks): an IDE, originally the     iPythonNotebook, operates in the browser Project     Jupyter</li> </ul> <p>K</p> <ul> <li>kernel: central component of most operating systems (OS)</li> <li>Kubernetes: an open source container orchestration platform     created by Google Kubernetes is often     referred to as <code>K8s</code></li> </ul> <p>L</p> <ul> <li>lib: a UNIX library</li> <li>linux: open source Unix-like operating system</li> </ul> <p>M</p> <ul> <li>makefile: a file containing a set of directives used by a make     build automation tool</li> <li>markdown: a lightweight markup language with plain text     formatting syntax</li> <li>metadata:: data about data, useful for searching and querying</li> <li>multi-thread: a process which runs on more than one CPU or GPU     core at the same time</li> <li>master node: responsible for deciding what runs on all of the     cluster's nodes. Can include scheduling workloads, like     containerized applications, and managing the workloads' lifecycle,     scaling, and upgrades. The master also manages network and storage     resources for those workloads</li> <li>Mac OS X: Apple's popular desktop OS</li> </ul> <p>N</p> <ul> <li>node: a computer, typically 1 or 2 core (with many threads)     server in a cloud or HPC center</li> </ul> <p>O</p> <ul> <li>ontology: formal naming and structural hierarchy used to     describe data, also called a knowledge     graph</li> <li>organization: a group, in the context of GitHub a place where     developers contribute code to repositories</li> <li>Operating System (OS): software that manages computer hardware,     software resources, and provides common services for computer     programs</li> <li>Open Science Grid (OSG): national, distributed computing     partnership for data-intensive research     opensciencegrid.org</li> <li>ORCID: Open Researcher and Contributor ID     (ORCiD), a persistent digital identifier that     distinguishes you from every other researcher</li> </ul> <p>P</p> <ul> <li>PaaS: Platform as Service run     and manage applications in cloud without complexity of developing it     yourself</li> <li>package: an app designed for a particular langauge</li> <li>package manager: a collection of software tools that automates     the process of installing, upgrading, configuring, and removing     computer programs for a computer's operating system in a consistent     manner</li> <li>Production: environment where users access the final code after     all of the updates and testing</li> <li>Python: interpreted, high-level, general-purpose programming     language Python.org</li> </ul> <p>Q</p> <ul> <li>QUAY.io: private Docker registry QUAY.io</li> </ul> <p>R</p> <ul> <li>R: data science programming language R Project</li> <li>recipe file: a file with installation scripts used for building     software such as containers, e.g. Dockerfile</li> <li>registry: a storage and content delivery system, such as that     used by Docker</li> <li>remote desktop: a VM with a graphic user interface accessed via     a browser</li> <li>repo(sitory): a directory structure for hosting code and data</li> <li>RST: ReStructuredText, a markdown type file</li> <li>ReadTheDocs: a web service for rendering documentation (that     this website uses) readthedocs.org and     readthedocs.com</li> <li>root: the administrative user on a linux kernel - use your     powers wisely</li> </ul> <p>S</p> <ul> <li>SaaS: Software as a Service web     based platform for using software</li> <li>schema: a metadata standard for labeling, tagging or coding for     recording &amp; cataloging information or structuring descriptive     records. see schema.org</li> <li>scrum: daily set of tasks and evalautions as part of a sprint.</li> <li>shell: is a command line interface program that runs other     programs (may be complex, technical programs or very simple programs     such as making a directory). These simple, stand-alone programs are     called commands</li> <li>Singularity: a container software, used widely on HPC, created     by SyLabs</li> <li>SLACK: Searchable Log of All Conversation and Knowledge, a team     communication tool slack.com</li> <li>sprint: set period of time during which specific work has to be     completed and made ready for review</li> <li>Singularity def file: (definition file) recipe for building a     Singualrity container</li> <li>Stage: environment that is as similar to the production     environment as can be for final testing</li> </ul> <p>T</p> <ul> <li>tar: software utility for collecting many files into one archive     file, often referred to as a tarball</li> <li>tensor: algebraic object that describes a linear mapping from     one set of algebraic objects to another</li> <li>terminal: a windowed emulator for directly enterinc commands to     a computer</li> <li>thread: a CPU process or a series of linked messages in a     discussion board</li> <li>tool: In the context of CyVerse Discovery Environment, a Docker     Container</li> <li>TPU: tensor processing unit</li> <li>Travis: Travis-CI, a continuous     integration software</li> </ul> <p>U</p> <ul> <li>Ubuntu: most popular Linux OS     distribution, based on Debian</li> <li>UNIX: operating system</li> <li>user: the profile under which applications are started and run,     <code>root</code> is the most powerful system administrator</li> </ul> <p>V</p> <ul> <li>VICE: Visual Interactive Computing     Environment -     Cyverse Data Science Workbench</li> <li>virtual machine: is a software computer that, like a physical     computer, runs an operating system and applications</li> </ul> <p>W</p> <ul> <li>waterfall: software development broken into linear sequential     phases, similar to a Gantt chart</li> <li>webGL: JavaScript API for rendering interactive 2D and 3D     graphics within any compatible web browser without the use of     plug-ins</li> <li>Windows: Microsoft's most popular desktop OS</li> <li>workspace: (vs. repo)</li> <li>worker node: A cluster typically has one or more nodes, which     are the worker machines that run your containerized applications and     other workloads. Each node is managed from the master, which     receives updates on each node's self-reported status.</li> </ul> <p>X</p> <ul> <li>XML: Extensible Markup Language, data interchange format that     uses human-readable text</li> </ul> <p>Y</p> <ul> <li>YAML: YAML Ain't Markup Language, data interchange format that     uses human-readable text</li> </ul> <p>Z</p> <ul> <li>ZenHub: team collaboration solution built directly into GitHub     that uses kanban style boards</li> <li>Zenodo: general-purpose open-access repository developed under     the European OpenAIRE program and operated by CERN</li> <li>zip: a compressed file format</li> <li>zsh: Z-Shell, now the default shell on     new Mac OS X</li> </ul>"},{"location":"installation/","title":"Pre-FOSS Setup","text":"<p>Welcome to FOSS Online, we're happy you're here! To get you ready to hit the ground running, please set up the prerequisite accounts and software listed below before the course starts.</p>"},{"location":"installation/#account-creation","title":"Account Creation","text":"<p>We will be using several services that require you to create a user account.</p> Account Notes  GitHub GitHub will be used to store lecture materials and your own work. We will use GitHub Education and its free features for hands-on.  Docker Link your GitHub account to the DockerHub.  Slack We use the Slack <code>cyverselearning</code> organization, you should have received an invitation via email. You can use Slack in the browser, but the desktop app is usually less buggy.  HackMD We will use HackMD in order to facilitate daily discussions, questions and general notes. Link your HackMD using your GitHub account <p>Link to  HackMD</p> <pre><code>https://hackmd.io/lJD96GCzQnWpxIX2UvwTNA?both\n</code></pre> Dual Monitors vs Side-by-Side <pre><code>We strongly recommend you have dual monitors set-up while attending virtual FOSS Zoom lessons.\n\nWe will be doing a lot of screen-sharing, and this will make your own interactive sessions less visible, or you will have to make them less than full screen.\n\nIf you only have one monitor, make sure to exit full screen mode on Zoom and your browser, so you can view everything side-by-side\n</code></pre>"},{"location":"installation/#required-software","title":"Required Software","text":"<p>You will need to have the following software installed on your personal computer:</p> Software Notes Web Browser  Chrome or  Firefox. Text Editor  VS Code or SublimeText <p>Attention  Windows users</p> <pre><code>Much of what we are going to be teaching is based on open-source software which operates on cloud and is incompatible with Windows OS.\n\nUnix-based systems such as Linux [:material-ubuntu: Ubuntu](https://ubuntu.com/){target=_blank} and [:material-apple: MacOS X](https://www.apple.com/macos/){target=_blank}, as many scientific tools require a Unix Operating System (OS).\n\nThere are a number of software that allow Windows users to execute Unix commands, however we recommend the use of [:material-microsoft-windows: Windows Subsystem for Linux (WSL) 2.0](https://docs.microsoft.com/en-us/windows/wsl/install){target=_blank}.\n\n[:material-microsoft-visual-studio-code: VS Code](https://code.visualstudio.com/download){target=_blank} is a Microsoft product and integrates seamlessly with Unix systems, we therefore strongly encourage you to install Code on your Windows OS.\n</code></pre>"},{"location":"schedule/","title":"Weekly Schedule","text":"<p>Thursdays 11 am - 1 pm Arizona Time.</p> <p>This schedule is tentative and subject to change</p>"},{"location":"schedule/#calendar","title":"Calendar","text":"Week Date Content Instructor(s) Week 0 Sept 7 pre-FOSS workshop:  - Unix shell basics  - Git/GitHub basics  - ChatGPT &amp; LLMs Michele Cosi &amp; Jeff Gillan Week 1 Sept 14 Workshop introduction:  - Intro to Open Science Tyson Swetnam, Michele Cosi, Jeff Gillan Week 2 Sept 21 Data management:  - FAIR data  - Data Management Plans  - Processing activity Jeff Gillan, Michele Cosi  Guest Speaker: Wade Bishop, UTK Week 3 Sept 28 - Project management  - Intro to CyVerse Michele Cosi, Tyson Swetnam Week 4 Oct 5 Documentation / Communication:  - Internal + External Documentation  - Internal + External Communication  - GitHub Pages websites Michele Cosi, Jeff Gillan Week 5 Oct 12 Version Control  - Version control as a philosophy  - GitHub functionality  Version control everything Michele Cosi,  Guest Speaker: Jason Williams, CSH Week 6 Oct 19 Reproducibility I:  - Software installation  - Software management Jeff Gillan, Michele Cosi Week 7 Oct 26 Reproducibility II:  - Brief intro to containers Michele Cosi, Jeffrey Gillan Week 8 Nov 2 Capstone Presentations"},{"location":"documentation/githubpages/","title":"GitHub Pages - quick start","text":"<p>This is a quick introduction to GitHub Pages, a simple way to use GitHub to set up a small website written in Markdown. This page won't do everything, but you can throw up a basic website, use themes, and extend it.</p> <ol> <li>Go to https://github.com/. Login, or if you don't have an account get one and login.</li> <li>Go to the \"+\" icon on the upper right and select New repository.</li> <li>Enter a name for your repository (e.g. \"profile\"). Enter a description, and leave the repository as public. Select \"Initialize this repository with a README\". If desired select a license. Finally click Create repository.</li> <li>Look for the Settings menu (upper right, next to a \"gear\" icon). Scroll down to GitHub Pages and choose master branch and save your selection. Then Choose a theme and select your theme. You will be asked to Commit changes.</li> <li>Your website will be visible at <code>https://GITHUBUSERNAME.github.io/REPONAME/</code>. (be sure to change GITHUBUSERNAME to your username, and REPONAME to the name you selected for your repo.)</li> <li>You can edit your website by editing the readme file as desired.</li> </ol> <p>Tip</p> <pre><code>You can preview how your [Markdown](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet) looks using and editor like [Markdown Plus](https://mdp.tylingsoft.com/).\n</code></pre>"},{"location":"final_project/overview/","title":"Capstone Project Overview","text":"<p>The capstone project for FOSS is designed to give you the opportunity to apply some of the skills and ideas from the rest of the course to one of your own projects, get support and feedback from your peers, and share your experiences with the rest of the attendees.</p>"},{"location":"final_project/overview/#objectives","title":"Objectives","text":"<ul> <li>\"Level up\" the openness of an existing or planned project</li> <li>Apply a skill or concept from FOSS</li> <li>Discuss your applied skills/concepts with groupmates</li> <li>Determine possible next steps to \"level up\" your project</li> <li>Share your experiences with the rest of the attendees</li> </ul>"},{"location":"final_project/overview/#description","title":"Description","text":""},{"location":"final_project/overview/#option-1","title":"Option 1","text":"<p>For the Fall 2023 capstone project, we will introduce hands-on exercises at the end of each FOSS session that will help crystalize the material learned that day. Over the 8 weeks of the course, you will be building and populating a Github repository or 'research object' for you own research projects. For example, for the session where we cover Data Management, we will have an exercise where you write a mini data management plan and post it in your Github Repo. </p> <p>Option 1 will be using the following website as reference: FOSS Reference Hub.</p>"},{"location":"final_project/overview/#option-2","title":"Option 2","text":"<p>For option 2, you can forego the week-to-week exercises. Instead, you will choose one (or more) skill(s) or concept(s) from FOSS and apply it to one of your own projects. </p> <p>For instance, you could write a Data Management Plan for an upcoming project proposal, or you could reorganize an existing project and put all the code onto GitHub. You could build a resume git.io web page, or you could try to containerize software. You should try to identify what level your project is currently at for a given topic, and attempt to move up a level. This means you can try out a skill or idea you've never used before, or go to a more advanced level for something you already do.</p> <p>You should have your skill/topic chosen by Week 6, and you will then enter your name / topic into a spreadsheet (shared during the week 6 session). We'll use this to help students find others working on similar projects.</p> <ul> <li>You can do a project completely solo</li> <li>You can work solo, but join a 'support group' to:<ol> <li>discuss your experiences applying your skill or concept</li> <li>give each other help with sticking point you may encounter</li> </ol> </li> <li>You can work directly with a FOSS colleague on a joint project</li> </ul>"},{"location":"final_project/overview/#final-presentations","title":"Final Presentations","text":"<p>Each student or group will deliver a short (5-10 minute) presentation to the rest of the class on week 8</p> <p>Your small group presentation should focus on the challenges and tips you may have for other FOSS attendees who want to utilize your skill or concept in the future. Here are some prompts that you should address during your presentation:</p> <ul> <li>What was the general topic or skill that members of your group worked on?</li> <li>What are some challenges you encountered while working on your projects?<ul> <li>Were you able to overcome these challenges? If so, how?</li> <li>Where did you look for help?</li> <li>Do any roadblocks remain? How might you try to overcome them?</li> </ul> </li> <li>Are there any new things you learned while working on your project?<ul> <li>Did you end up using any new or different tools?</li> </ul> </li> <li>What are some tips you might have for other FOSS attendees who want to work on the same topic/skill in the future?<ul> <li>Are there any pitfalls to avoid?</li> </ul> </li> <li>What things do you want to do next?<ul> <li>How might you \"level up\" in the current topic/skill compared to your project's current state?</li> <li>Are there any other FOSS skills that you want to tackle next? If so, how might they integrate with the topic/skill you focused on for your project?</li> </ul> </li> </ul>"},{"location":"final_project/overview/#examples","title":"Examples","text":"<p>Links to previous' year capstone projects will be posted in the FOSS HackMD. Stay tuned!</p>"}]}